{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 dataset classification with CNNs\n",
    "\n",
    "Author: Tanwi Mallick, adapting codes from Bethany Lusch, Prasanna Balprakash, Corey Adams, and Kyle Felker\n",
    "\n",
    "In this notebook, we'll continue the CIFAR-10 problem using the Keras API (as included in the TensorFlow library) and incorporating convolutional layers.\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 20:00:29.959412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 20:00:31.781878: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-04 20:00:32.868465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2022-10-04 20:00:32.868496: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-04 20:00:33.090770: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-04 20:00:44.618836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2022-10-04 20:00:44.619338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2022-10-04 20:00:44.619348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 data set\n",
    "\n",
    "Again we'll load the cifar10 data set. CIFAR-10 dataset contains 32x32 color images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. If you haven't downloaded it already, it could take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(numpy.float32)\n",
    "x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test  /= 255.\n",
    "\n",
    "y_train = y_train.astype(numpy.int32)\n",
    "y_test  = y_test.astype(numpy.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we won't flatten the images. \n",
    "\n",
    "The training data (`X_train`) is a 3rd-order tensor of size (50000, 32, 32), i.e. it consists of 50000 images of size 32x32 pixels. \n",
    "\n",
    "`y_train` is a 50000-dimensional vector containing the correct classes ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') for each training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network (CNN)\n",
    "\n",
    "CNN is a type of deep learning model for processing data that has a grid pattern, such as images.\n",
    "\n",
    "Let's use a small model that includes convolutional layers\n",
    "\n",
    "- The Conv2D layers operate on 2D matrices so we input the digit images directly to the model.\n",
    "    - The two Conv2D layers belows learn 32 and 64 filters respectively. \n",
    "    - They are learning filters for 3x3 windows.\n",
    "- The MaxPooling2D layer reduces the spatial dimensions, that is, makes the image smaller.\n",
    "    - It downsamples by taking the maximum value in the window \n",
    "    - The pool size of (2, 2) below means the windows are 2x2. \n",
    "    - Helps in extracting important features and reduce computation\n",
    "- The Flatten layer flattens the 2D matrices into vectors, so we can then switch to Dense layers as in the MLP model.\n",
    "\n",
    "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conv layer](images/conv_layer.png)\n",
    "Image credit: [Jason Brownlee](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conv layer](images/conv.png)\n",
    "Image credit: [Anh H. Reynolds](https://anhreynolds.com/blogs/cnn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/MaxpoolSample2.png\" width=\"600\" hight=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Classifier(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, activation=tf.nn.tanh):\n",
    "        tf.keras.models.Model.__init__(self)\n",
    "\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
    "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
    "        self.dense_5 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.drop_6 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense_7 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_3(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = self.dense_5(x)\n",
    "        x = self.drop_6(x)\n",
    "        x = self.dense_7(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a concise way to train the network, like we did in the previous notebook. We'll see a more verbose approach below that allows more performance tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    cnn_model = CIFAR10Classifier()\n",
    "\n",
    "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
    "    return history, cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "391/391 [==============================] - 23s 57ms/step - loss: 1.7640 - accuracy: 0.3449\n",
      "Epoch 2/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 1.4627 - accuracy: 0.4682\n",
      "Epoch 3/30\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.3327 - accuracy: 0.5172\n",
      "Epoch 4/30\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 1.2469 - accuracy: 0.5503\n",
      "Epoch 5/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.1927 - accuracy: 0.5729\n",
      "Epoch 6/30\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.1417 - accuracy: 0.5932\n",
      "Epoch 7/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.0911 - accuracy: 0.6088\n",
      "Epoch 8/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.0580 - accuracy: 0.6214\n",
      "Epoch 9/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 1.0201 - accuracy: 0.6336\n",
      "Epoch 10/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.9890 - accuracy: 0.6474\n",
      "Epoch 11/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.9649 - accuracy: 0.6544\n",
      "Epoch 12/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.9299 - accuracy: 0.6656\n",
      "Epoch 13/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.9062 - accuracy: 0.6723\n",
      "Epoch 14/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.8792 - accuracy: 0.6806\n",
      "Epoch 15/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.8519 - accuracy: 0.6921\n",
      "Epoch 16/30\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.8322 - accuracy: 0.6998\n",
      "Epoch 17/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.8201 - accuracy: 0.7049\n",
      "Epoch 18/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.7990 - accuracy: 0.7072\n",
      "Epoch 19/30\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 0.7842 - accuracy: 0.7147\n",
      "Epoch 20/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.7604 - accuracy: 0.7232\n",
      "Epoch 21/30\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.7532 - accuracy: 0.7265\n",
      "Epoch 22/30\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.7358 - accuracy: 0.7318\n",
      "Epoch 23/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.7296 - accuracy: 0.7307\n",
      "Epoch 24/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.7167 - accuracy: 0.7358\n",
      "Epoch 25/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.7083 - accuracy: 0.7411\n",
      "Epoch 26/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.6907 - accuracy: 0.7452\n",
      "Epoch 27/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.6854 - accuracy: 0.7477\n",
      "Epoch 28/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.6711 - accuracy: 0.7511\n",
      "Epoch 29/30\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 0.6648 - accuracy: 0.7545\n",
      "Epoch 30/30\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 0.6464 - accuracy: 0.7609\n"
     ]
    }
   ],
   "source": [
    "# This took 55 seconds per epoch on my laptop\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "lr = .01\n",
    "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for test data.  The model should be better than the non-convolutional model even if you're only patient enough for three epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'])\n",
    "plt.title('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With enough training epochs, the test accuracy should exceed 99%.\n",
    "\n",
    "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). Even more results can be found [here](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.9078 - accuracy: 0.7091 - 2s/epoch - 6ms/step\n",
      "accuracy: 70.91%\n",
      "CPU times: user 3.86 s, sys: 104 ms, total: 3.96 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
    "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also again check the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows: true classes; columns: predicted classes):\n",
      "\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "[[671  29  75  22  18  15  11  25  94  40]\n",
      " [ 31 743  10  13   6   7   8  14  44 124]\n",
      " [ 80  15 362  62 176 133  71  71   8  22]\n",
      " [ 19  10  86 350  45 282  86  88   9  25]\n",
      " [ 41   8 135  59 442  77  76 148   8   6]\n",
      " [ 15   4  75 112  35 609  30 107   9   4]\n",
      " [  8   8  64  95  69  47 646  40   4  19]\n",
      " [ 17   4  30  34  41 121  17 707   5  24]\n",
      " [165  81  30  15   2  21   6  17 614  49]\n",
      " [ 33 174  13  20   8  16  16  57  56 607]]\n",
      "\n",
      "Classification accuracy for each class:\n",
      "\n",
      "0: 0.6710\n",
      "1: 0.7430\n",
      "2: 0.3620\n",
      "3: 0.3500\n",
      "4: 0.4420\n",
      "5: 0.6090\n",
      "6: 0.6460\n",
      "7: 0.7070\n",
      "8: 0.6140\n",
      "9: 0.6070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
    "predictions = cnn_model.predict(x_test)\n",
    "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
    "print(cm); print()\n",
    "\n",
    "print('Classification accuracy for each class:'); print()\n",
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More verbose training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach explicitly handles the looping over data. It will be helpful this afternoon for diving in and optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    # if labels are integers, use sparse categorical crossentropy\n",
    "    # network's final layer is softmax, so from_logtis=False\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    # if labels are one-hot encoded, use standard crossentropy\n",
    "\n",
    "    return scce(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, batch_data, y_true):\n",
    "    y_pred = model(batch_data)\n",
    "    loss = compute_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function that will manage the training loop for us:\n",
    "\n",
    "def train_loop(batch_size, n_training_epochs, model, opt):\n",
    "    \n",
    "    @tf.function()\n",
    "    def train_iteration(data, y_true, model, opt):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model, data, y_true)\n",
    "\n",
    "        trainable_vars = model.trainable_variables\n",
    "\n",
    "        # Apply the update to the network (one at a time):\n",
    "        grads = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        opt.apply_gradients(zip(grads, trainable_vars))\n",
    "        return loss\n",
    "\n",
    "    for i_epoch in range(n_training_epochs):\n",
    "        print(\"beginning epoch %d\" % i_epoch)\n",
    "        start = time.time()\n",
    "\n",
    "        epoch_steps = int(50000/batch_size)\n",
    "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
    "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "        \n",
    "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
    "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
    "            loss = train_iteration(batch_data, y_true, model, opt)\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    mnist_model = CIFAR10Classifier()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(_lr)\n",
    "\n",
    "    train_loop(_batch_size, _n_training_epochs, mnist_model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning epoch 0\n",
      "took 17.2 seconds for epoch #0\n",
      "beginning epoch 1\n",
      "took 16.8 seconds for epoch #1\n",
      "beginning epoch 2\n",
      "took 17.2 seconds for epoch #2\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset.shuffle(50000)\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 3\n",
    "lr = .01\n",
    "train_network(batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: improve the accuracy of this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update this notebook to ensure more accuracy. How high can it be raised? Changes like increasing the number of epochs, altering the learning weight, altering the number of neurons the hidden layer, chnaging the optimizer, etc. could be made directly in the notebook. You can also change the model specification by expanding the network's layer. The current notebook's training accuracy is roughly 58.69%, although it varies randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
